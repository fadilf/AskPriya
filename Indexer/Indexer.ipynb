{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index import download_loader\n",
    "import re\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext, StorageContext\n",
    "from llama_index.vector_stores import PGVectorStore\n",
    "from os import environ\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.vertex import Vertex\n",
    "import google.auth\n",
    "from palm_multi import PaLMMultiEmbeddings\n",
    "import psycopg2\n",
    "from typing import List\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as per recommendation from @freylis, compile once only\n",
    "CLEANR = re.compile('<.*?>') \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the markdown reader from the hub\n",
    "MarkdownReader = download_loader(\"MarkdownReader\")\n",
    "markdownreader = MarkdownReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "df_pre = pd.read_csv(\"./uscis.csv\").dropna()\n",
    "for row in range(len(df_pre)):\n",
    "    row_data = df_pre.iloc[row]\n",
    "    heading = row_data.heading\n",
    "    link = row_data.link\n",
    "    text = row_data.text\n",
    "    new_text = cleanhtml(text)\n",
    "    new_docs = markdownreader.load_data(file=None, content=new_text, extra_info={\n",
    "        \"page\": heading,\n",
    "        \"link\": link,\n",
    "    })\n",
    "    docs.extend(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayedPaLMEmbedding(PaLMMultiEmbeddings):\n",
    "    _delay = 1\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        sleep(self._delay)\n",
    "        return super()._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        sleep(self._delay)\n",
    "        return await super()._aget_query_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        sleep(self._delay)\n",
    "        return super()._get_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        sleep(self._delay)\n",
    "        return super()._aget_text_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        sleep(self._delay)\n",
    "        return super()._get_text_embeddings(texts)\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        sleep(self._delay)\n",
    "        return await super()._aget_text_embeddings(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = DelayedPaLMEmbedding(embed_batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unix_socket = '/cloudsql/{}'.format(\"ask-prita:us-central1:ask-priya-store\")\n",
    "db_user = \"postgres\"\n",
    "db_password = environ[\"DB_PASSWORD\"]\n",
    "db_name = \"askpriyadb4\"\n",
    "db_host = environ[\"DB_HOST\"]\n",
    "db_port = 5432\n",
    "CLOUD_SQL_CONNECTION_NAME = \"ask-prita:us-central1:ask-priya-store\"\n",
    "connection_string = f\"user={db_user} password={db_password} host={db_host} port={db_port}\"\n",
    "conn = psycopg2.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=db_host,\n",
    "    password=db_password,\n",
    "    port=db_port,\n",
    "    user=db_user,\n",
    "    table_name=\"uscis\",\n",
    "    embed_dim=768,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Vertex(model=\"chat-bison\", temperature=0, additional_kwargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\Personal\\AskPriya2\\Indexer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 3538/3538 [00:05<00:00, 590.32it/s] \n",
      "Generating embeddings: 100%|██████████| 2048/2048 [08:07<00:00,  4.20it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [08:13<00:00,  4.15it/s]\n",
      "Generating embeddings: 100%|██████████| 92/92 [00:22<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=docs,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
